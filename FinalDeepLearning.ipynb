{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388c6b1b-430d-4f12-aecf-4161b2beb9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fb/t22rn_kd4dz6_ntbgp5vldwc0000gn/T/ipykernel_24220/3836138609.py:5: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  matches = pd.read_csv(\"Matches.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of matches: (230557, 48)\n",
      "After keeping FTResult in {H,D,A}: (230554, 49)\n",
      "After filtering Division=E0 and 2005–2024: (7543, 49)\n",
      "After removing draws: (5711, 50)\n",
      "home_win value counts:\n",
      "home_win\n",
      "1    3460\n",
      "0    2251\n",
      "Name: count, dtype: int64\n",
      "Number of numeric feature columns used: 29\n",
      "Sample of feature columns: ['HomeElo', 'AwayElo', 'Form3Home', 'Form5Home', 'Form3Away', 'Form5Away', 'OddHome', 'OddDraw', 'OddAway', 'MaxHome', 'MaxDraw', 'MaxAway', 'Over25', 'Under25', 'MaxOver25', 'MaxUnder25', 'HandiSize', 'HandiHome', 'HandiAway', 'C_LTH']\n",
      "Final shape of X_full: (5601, 29)\n",
      "Final shape of y_full: (5601,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeElo</th>\n",
       "      <th>AwayElo</th>\n",
       "      <th>Form3Home</th>\n",
       "      <th>Form5Home</th>\n",
       "      <th>Form3Away</th>\n",
       "      <th>Form5Away</th>\n",
       "      <th>OddHome</th>\n",
       "      <th>OddDraw</th>\n",
       "      <th>OddAway</th>\n",
       "      <th>MaxHome</th>\n",
       "      <th>...</th>\n",
       "      <th>C_LTH</th>\n",
       "      <th>C_LTA</th>\n",
       "      <th>C_VHD</th>\n",
       "      <th>C_VAD</th>\n",
       "      <th>C_HTB</th>\n",
       "      <th>C_PHB</th>\n",
       "      <th>Year</th>\n",
       "      <th>p_home</th>\n",
       "      <th>p_draw</th>\n",
       "      <th>p_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27662</th>\n",
       "      <td>1702.64</td>\n",
       "      <td>1862.81</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.72</td>\n",
       "      <td>5.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.7048</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.185958</td>\n",
       "      <td>0.273467</td>\n",
       "      <td>0.540575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27666</th>\n",
       "      <td>1638.74</td>\n",
       "      <td>1705.45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5329</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.337909</td>\n",
       "      <td>0.290391</td>\n",
       "      <td>0.371700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27667</th>\n",
       "      <td>1628.42</td>\n",
       "      <td>1657.04</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.5768</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.390951</td>\n",
       "      <td>0.289548</td>\n",
       "      <td>0.319501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27668</th>\n",
       "      <td>1573.54</td>\n",
       "      <td>1682.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.60</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.5646</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.371700</td>\n",
       "      <td>0.290391</td>\n",
       "      <td>0.337909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27735</th>\n",
       "      <td>1911.87</td>\n",
       "      <td>1723.82</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.662983</td>\n",
       "      <td>0.220994</td>\n",
       "      <td>0.116022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HomeElo  AwayElo  Form3Home  Form5Home  Form3Away  Form5Away  OddHome  \\\n",
       "27662  1702.64  1862.81        6.0        6.0        1.0        5.0     5.00   \n",
       "27666  1638.74  1705.45        4.0        5.0        5.0        9.0     2.75   \n",
       "27667  1628.42  1657.04        7.0       10.0        1.0        2.0     2.37   \n",
       "27668  1573.54  1682.25        7.0       11.0        7.0        8.0     2.50   \n",
       "27735  1911.87  1723.82        7.0       13.0        0.0        4.0     1.40   \n",
       "\n",
       "       OddDraw  OddAway  MaxHome  ...   C_LTH   C_LTA   C_VHD   C_VAD   C_HTB  \\\n",
       "27662      3.4     1.72     5.65  ...  0.0906  0.7048  0.0410  0.0191  0.0887   \n",
       "27666      3.2     2.50     3.25  ...  0.5329  0.0171  0.0205  0.0531  0.1235   \n",
       "27667      3.2     2.90     2.60  ...  0.0941  0.1359  0.0100  0.5768  0.1287   \n",
       "27668      3.2     2.75     2.60  ...  0.2148  0.0575  0.5646  0.0099  0.0249   \n",
       "27735      4.2     8.00     1.50  ...  0.0103  0.0099  0.0099  0.9153  0.0449   \n",
       "\n",
       "        C_PHB  Year    p_home    p_draw    p_away  \n",
       "27662  0.0559  2005  0.185958  0.273467  0.540575  \n",
       "27666  0.2530  2005  0.337909  0.290391  0.371700  \n",
       "27667  0.0545  2005  0.390951  0.289548  0.319501  \n",
       "27668  0.1282  2005  0.371700  0.290391  0.337909  \n",
       "27735  0.0099  2005  0.662983  0.220994  0.116022  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load full matches data\n",
    "matches = pd.read_csv(\"Matches.csv\")\n",
    "print(\"Original shape of matches:\", matches.shape)\n",
    "\n",
    "# Make date usable and extract year\n",
    "matches[\"MatchDate\"] = pd.to_datetime(matches[\"MatchDate\"], errors=\"coerce\")\n",
    "matches[\"Year\"] = matches[\"MatchDate\"].dt.year\n",
    "\n",
    "# Keep only rows with valid full-time result\n",
    "valid_results = [\"H\", \"D\", \"A\"]\n",
    "matches = matches[matches[\"FTResult\"].isin(valid_results)].copy()\n",
    "print(\"After keeping FTResult in {H,D,A}:\", matches.shape)\n",
    "\n",
    "# only on Premier League, 2005–2024\n",
    "matches = matches[matches[\"Division\"] == \"E0\"].copy()\n",
    "matches = matches[(matches[\"Year\"] >= 2005) & (matches[\"Year\"] <= 2024)].copy()\n",
    "print(\"After filtering Division=E0 and 2005–2024:\", matches.shape)\n",
    "\n",
    "# Remove draws (we only predict home vs away)\n",
    "matches_no_draw = matches[matches[\"FTResult\"] != \"D\"].copy()\n",
    "\n",
    "# Target: 1 = home win, 0 = away win\n",
    "matches_no_draw[\"home_win\"] = (matches_no_draw[\"FTResult\"] == \"H\").astype(int)\n",
    "\n",
    "print(\"After removing draws:\", matches_no_draw.shape)\n",
    "print(\"home_win value counts:\")\n",
    "print(matches_no_draw[\"home_win\"].value_counts())\n",
    "\n",
    "# If odds are present, convert them to implied probabilities\n",
    "if all(col in matches_no_draw.columns for col in [\"OddHome\", \"OddDraw\", \"OddAway\"]):\n",
    "\n",
    "    def odds_to_probs(row):\n",
    "        oh, od, oa = row[\"OddHome\"], row[\"OddDraw\"], row[\"OddAway\"]\n",
    "        if oh <= 0 or od <= 0 or oa <= 0:\n",
    "            return pd.Series([np.nan, np.nan, np.nan])\n",
    "        inv = np.array([1/oh, 1/od, 1/oa], dtype=float)\n",
    "        p = inv / inv.sum()\n",
    "        return pd.Series(p)\n",
    "\n",
    "    matches_no_draw[[\"p_home\", \"p_draw\", \"p_away\"]] = (\n",
    "        matches_no_draw[[\"OddHome\", \"OddDraw\", \"OddAway\"]]\n",
    "        .apply(odds_to_probs, axis=1)\n",
    "    )\n",
    "\n",
    "# Columns that are \"after the match\", NOT be used as inputs\n",
    "leak_cols = [\n",
    "    \"FTResult\",\n",
    "    \"home_win\",\n",
    "    \"FTHome\", \"FTAway\",\n",
    "    \"HTHome\", \"HTAway\", \"HTResult\",\n",
    "    \"HomeShots\", \"AwayShots\",\n",
    "    \"HomeTarget\", \"AwayTarget\",\n",
    "    \"HomeFouls\", \"AwayFouls\",\n",
    "    \"HomeCorners\", \"AwayCorners\",\n",
    "    \"HomeYellow\", \"AwayYellow\",\n",
    "    \"HomeRed\", \"AwayRed\",\n",
    "]\n",
    "\n",
    "# All numeric columns\n",
    "numeric_cols = [\n",
    "    col for col in matches_no_draw.columns\n",
    "    if pd.api.types.is_numeric_dtype(matches_no_draw[col])\n",
    "]\n",
    "\n",
    "# Features = numeric columns minus leakage\n",
    "feature_cols_all = [\n",
    "    col for col in numeric_cols\n",
    "    if col not in leak_cols\n",
    "]\n",
    "\n",
    "print(\"Number of numeric feature columns used:\", len(feature_cols_all))\n",
    "print(\"Sample of feature columns:\", feature_cols_all[:20])\n",
    "\n",
    "# Build full feature matrix and label\n",
    "X_full = matches_no_draw[feature_cols_all].copy()\n",
    "y_full = matches_no_draw[\"home_win\"].copy()\n",
    "\n",
    "# Drop any rows with missing values in X or y\n",
    "data_full = pd.concat([X_full, y_full], axis=1).dropna()\n",
    "X_full = data_full[feature_cols_all]\n",
    "y_full = data_full[\"home_win\"]\n",
    "\n",
    "print(\"Final shape of X_full:\", X_full.shape)\n",
    "print(\"Final shape of y_full:\", y_full.shape)\n",
    "\n",
    "X_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "092704d3-dfbc-4639-b0d9-bb456698b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "301b40b4-c5ac-4b84-9950-507f36d655a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much stronger / in-form home team is\n",
    "\n",
    "# Elo difference (home strength - away strength)\n",
    "matches_no_draw[\"EloDiff\"] = matches_no_draw[\"HomeElo\"] - matches_no_draw[\"AwayElo\"]\n",
    "\n",
    "# Recent form differences (points in last 3 and 5 games)\n",
    "matches_no_draw[\"FormDiff3\"] = matches_no_draw[\"Form3Home\"] - matches_no_draw[\"Form3Away\"]\n",
    "matches_no_draw[\"FormDiff5\"] = matches_no_draw[\"Form5Home\"] - matches_no_draw[\"Form5Away\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "752ad590-5e12-46c4-a78f-3c505ef4431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4480\n",
      "Test size: 1121\n",
      "Inner train size: 3584\n",
      "Validation size: 896\n",
      "Scaled shapes: (3584, 29) (896, 29) (1121, 29)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Outer train/test split\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "    X_full,\n",
    "    y_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_full\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train_full.shape[0])\n",
    "print(\"Test size:\", X_test_full.shape[0])\n",
    "\n",
    "# Inner split: train vs validation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(\"Inner train size:\", X_tr.shape[0])\n",
    "print(\"Validation size:\", X_val.shape[0])\n",
    "\n",
    "# Scale features (fit on inner train only)\n",
    "scaler = StandardScaler()\n",
    "X_tr_scaled   = scaler.fit_transform(X_tr)\n",
    "X_val_scaled  = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test_full)\n",
    "\n",
    "print(\"Scaled shapes:\", X_tr_scaled.shape, X_val_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0f8ffc3-7d95-49da-ba5a-18c9be20c44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,689</span> (198.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,689\u001b[0m (198.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,793</span> (194.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,793\u001b[0m (194.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_dim = X_tr_scaled.shape[1]\n",
    "print(\"Number of input features:\", input_dim)\n",
    "\n",
    "mlp_model = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "\n",
    "    # Bigger first hidden layer\n",
    "    layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Second hidden layer\n",
    "    layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Third hidden layer\n",
    "    layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(1e-4)),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    # Output layer: probability that home team wins\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "mlp_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5be76930-0195-4c13-88ac-18d83797e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    \"best_val_model.keras\",      \n",
    "    monitor=\"val_accuracy\",      \n",
    "    mode=\"max\",                  \n",
    "    save_best_only=True,        \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc6f812a-db15-48bc-8b0d-2f2b946f6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6953 - loss: 0.5924\n",
      "Epoch 1: val_accuracy improved from None to 0.70982, saving model to best_val_model.keras\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7299 - loss: 0.5574 - val_accuracy: 0.7098 - val_loss: 0.5875\n",
      "Epoch 2/90\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7070 - loss: 0.5833\n",
      "Epoch 2: val_accuracy did not improve from 0.70982\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5562 - val_accuracy: 0.7054 - val_loss: 0.5878\n",
      "Epoch 3/90\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7344 - loss: 0.5745\n",
      "Epoch 3: val_accuracy did not improve from 0.70982\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5504 - val_accuracy: 0.7020 - val_loss: 0.5888\n",
      "Epoch 4/90\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6953 - loss: 0.5740\n",
      "Epoch 4: val_accuracy did not improve from 0.70982\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7254 - loss: 0.5569 - val_accuracy: 0.7031 - val_loss: 0.5890\n",
      "Epoch 5/90\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6953 - loss: 0.5950\n",
      "Epoch 5: val_accuracy did not improve from 0.70982\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5507 - val_accuracy: 0.7065 - val_loss: 0.5894\n",
      "Epoch 6/90\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6914 - loss: 0.5867\n",
      "Epoch 6: val_accuracy did not improve from 0.70982\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7313 - loss: 0.5525 - val_accuracy: 0.7054 - val_loss: 0.5901\n",
      "Epoch 7/90\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7266 - loss: 0.5460\n",
      "Epoch 7: val_accuracy did not improve from 0.70982\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5517 - val_accuracy: 0.7031 - val_loss: 0.5913\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = mlp_model.fit(\n",
    "    X_tr_scaled, y_tr,\n",
    "    validation_data=(X_val_scaled, y_val),\n",
    "    epochs=90,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop, checkpoint],\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fbada73a-535c-48b7-9a81-f01ff8fdd527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step\n",
      "Best threshold on validation set: 0.48\n",
      "Best validation accuracy: 0.71875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Probabilities on validation set\n",
    "y_val_proba = mlp_model.predict(X_val_scaled).ravel()\n",
    "\n",
    "best_t = 0.1\n",
    "best_acc = 0.0\n",
    "\n",
    "# Try thresholds between 0.3 and 0.7\n",
    "for t in np.linspace(0.3, 0.7, 41):   # step of 0.01\n",
    "    y_val_pred = (y_val_proba >= t).astype(int)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_t = t\n",
    "\n",
    "print(\"Best threshold on validation set:\", best_t)\n",
    "print(\"Best validation accuracy:\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7558fbd3-fc77-4839-8c9b-91df4e708fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Test accuracy (best val model, t=0.5): 0.7234611953612846\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.55      0.61       443\n",
      "           1       0.74      0.83      0.79       678\n",
      "\n",
      "    accuracy                           0.72      1121\n",
      "   macro avg       0.71      0.69      0.70      1121\n",
      "weighted avg       0.72      0.72      0.72      1121\n",
      "\n",
      "Confusion matrix:\n",
      "[[245 198]\n",
      " [112 566]]\n",
      "\n",
      "ROC AUC: 0.7857627998961224\n"
     ]
    }
   ],
   "source": [
    "best_mlp = keras.models.load_model(\"best_val_model.keras\")\n",
    "\n",
    "y_test_proba = best_mlp.predict(X_test_scaled).ravel()\n",
    "y_test_pred  = (y_test_proba >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "test_acc = accuracy_score(y_test_full, y_test_pred)\n",
    "print(\"Test accuracy (best val model, t=0.5):\", test_acc)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test_full, y_test_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test_full, y_test_pred))\n",
    "\n",
    "auc = roc_auc_score(y_test_full, y_test_proba)\n",
    "print(\"\\nROC AUC:\", auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
